{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fe4629",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 09:22:52,338 | INFO     | sql_loader.omop_alchemy.config | Environment variables loaded from .env file\n",
      "2026-01-12 09:22:52,339 | INFO     | sql_loader.omop_alchemy.config | Database engine configured\n"
     ]
    }
   ],
   "source": [
    "import sqlalchemy as sa\n",
    "import pandas as pd\n",
    "\n",
    "from orm_loader.helpers import configure_logging, bootstrap, explain_sqlite_fk_error, bulk_load_context, configure_logging\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy.exc import IntegrityError\n",
    "\n",
    "from omop_alchemy import get_engine_name, load_environment, TEST_PATH, ROOT_PATH\n",
    "\n",
    "from omop_alchemy.cdm.model.vocabulary import (\n",
    "    Domain,\n",
    "    Vocabulary,\n",
    "    Concept_Class,\n",
    "    Relationship,\n",
    "    Concept,\n",
    "    Concept_Ancestor,\n",
    "    Concept_Relationship,\n",
    "    Concept_Synonym,\n",
    "    Concept_Synonym,\n",
    ")\n",
    "\n",
    "ATHENA_INITIAL_LOAD = [\n",
    "    Domain,\n",
    "    Vocabulary,\n",
    "    Concept_Class,\n",
    "    Relationship,\n",
    "    Concept\n",
    "]\n",
    "\n",
    "ATHENA_SUBSEQUENT_LOAD = [\n",
    "    Concept_Ancestor,\n",
    "    Concept_Relationship\n",
    "]\n",
    "\n",
    "from random import randint, choice\n",
    "import numpy as np\n",
    "\n",
    "from sqlalchemy.orm import Session\n",
    "from omop_alchemy.cdm.model.health_system import Location, Care_Site, Provider, Visit_Detail, Visit_Occurrence\n",
    "from omop_alchemy.cdm.model.clinical import Person, Condition_Occurrence, Procedure_Occurrence, Death, Specimen, Drug_Exposure, Measurement, Observation\n",
    "from omop_alchemy.cdm.model.structural import Episode, Episode_Event\n",
    "from omop_alchemy.cdm.model.derived import Observation_Period\n",
    "from datetime import date, timedelta\n",
    "\n",
    "configure_logging()\n",
    "load_environment()\n",
    "\n",
    "engine_string = get_engine_name()\n",
    "engine = sa.create_engine(engine_string, future=True, echo=False)\n",
    "bootstrap(engine, create=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63f727bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2157e39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Session = sessionmaker(bind=engine, future=True)\n",
    "session = Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433ced72",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = TEST_PATH / \"fixtures\" / \"athena_source\"\n",
    "\n",
    "# uncomment this line if you want to load the full athena source from env var\n",
    "# instead of the minimal test fixture set for rapid access\n",
    "\n",
    "# base_path = Path(os.environ['SOURCE_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82601899",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found 1 rows with unexpected nulls in vocabulary.vocabulary_id\n",
      "Found 34 rows with unexpected nulls in concept.concept_name\n",
      "Found 1 rows with unexpected nulls in concept.vocabulary_id\n",
      "Found 1 rows with unexpected nulls in concept.concept_code\n"
     ]
    }
   ],
   "source": [
    "# Initial load of core vocabulary tables - use bulk load to ensure mutual FK constraints are handled (trusted sources only)\n",
    "with bulk_load_context(session):\n",
    "    for model in ATHENA_INITIAL_LOAD:\n",
    "        _ = model.load_csv(\n",
    "            session,\n",
    "            base_path / f\"{model.__tablename__.upper()}.csv\",\n",
    "            dedupe=True,\n",
    "        )\n",
    "    session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf65010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can still turn off FK checks for speed but mutual dependency is not an issue for this one - commit after each chunk\n",
    "with bulk_load_context(session):\n",
    "    for model in ATHENA_SUBSEQUENT_LOAD:\n",
    "        _ = model.load_csv(\n",
    "            session,\n",
    "            base_path / f\"{model.__tablename__.upper()}.csv\",\n",
    "            dedupe=True,\n",
    "            chunksize=5000,\n",
    "            commit_on_chunk=True,\n",
    "        )\n",
    "        session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a6ec9ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dropping 5000 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 20 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 17 rows from concept_synonym that already exist in the database\n",
      "Dropping 7 rows from concept_synonym that already exist in the database\n",
      "Dropping 5 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Found 1 rows with unexpected nulls in concept_synonym.concept_synonym_name\n",
      "Dropping 20 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 18 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 12 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 13 rows from concept_synonym that already exist in the database\n",
      "Dropping 9 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 6 rows from concept_synonym that already exist in the database\n",
      "Dropping 4 rows from concept_synonym that already exist in the database\n",
      "Dropping 17 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 15 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 6 rows from concept_synonym that already exist in the database\n",
      "Dropping 14 rows from concept_synonym that already exist in the database\n",
      "Dropping 4 rows from concept_synonym that already exist in the database\n",
      "Dropping 6 rows from concept_synonym that already exist in the database\n",
      "Dropping 11 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 5 rows from concept_synonym that already exist in the database\n",
      "Dropping 24 rows from concept_synonym that already exist in the database\n",
      "Dropping 8 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 5 rows from concept_synonym that already exist in the database\n",
      "Dropping 16 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 5 rows from concept_synonym that already exist in the database\n",
      "Dropping 23 rows from concept_synonym that already exist in the database\n",
      "Dropping 8 rows from concept_synonym that already exist in the database\n",
      "Dropping 5 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 11 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 4 rows from concept_synonym that already exist in the database\n",
      "Dropping 18 rows from concept_synonym that already exist in the database\n",
      "Dropping 6 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 12 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 14 rows from concept_synonym that already exist in the database\n",
      "Dropping 6 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 12 rows from concept_synonym that already exist in the database\n",
      "Dropping 6 rows from concept_synonym that already exist in the database\n",
      "Dropping 26 rows from concept_synonym that already exist in the database\n",
      "Dropping 8 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 12 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 12 rows from concept_synonym that already exist in the database\n",
      "Dropping 6 rows from concept_synonym that already exist in the database\n",
      "Dropping 20 rows from concept_synonym that already exist in the database\n",
      "Dropping 6 rows from concept_synonym that already exist in the database\n",
      "Dropping 12 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 13 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 20 rows from concept_synonym that already exist in the database\n",
      "Dropping 5 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 13 rows from concept_synonym that already exist in the database\n",
      "Dropping 6 rows from concept_synonym that already exist in the database\n",
      "Dropping 9 rows from concept_synonym that already exist in the database\n",
      "Dropping 18 rows from concept_synonym that already exist in the database\n",
      "Dropping 5 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 5 rows from concept_synonym that already exist in the database\n",
      "Dropping 8 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 16 rows from concept_synonym that already exist in the database\n",
      "Dropping 4 rows from concept_synonym that already exist in the database\n",
      "Dropping 4 rows from concept_synonym that already exist in the database\n",
      "Dropping 8 rows from concept_synonym that already exist in the database\n",
      "Dropping 4 rows from concept_synonym that already exist in the database\n",
      "Dropping 13 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 16 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 17 rows from concept_synonym that already exist in the database\n",
      "Dropping 6 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 17 rows from concept_synonym that already exist in the database\n",
      "Dropping 5 rows from concept_synonym that already exist in the database\n",
      "Dropping 18 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 14 rows from concept_synonym that already exist in the database\n",
      "Dropping 4 rows from concept_synonym that already exist in the database\n",
      "Dropping 4 rows from concept_synonym that already exist in the database\n",
      "Dropping 12 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 5 rows from concept_synonym that already exist in the database\n",
      "Dropping 19 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 8 rows from concept_synonym that already exist in the database\n",
      "Dropping 9 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 8 rows from concept_synonym that already exist in the database\n",
      "Dropping 11 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 12 rows from concept_synonym that already exist in the database\n",
      "Dropping 11 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 7 rows from concept_synonym that already exist in the database\n",
      "Dropping 4 rows from concept_synonym that already exist in the database\n",
      "Dropping 4 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 8 rows from concept_synonym that already exist in the database\n",
      "Dropping 18 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 7 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 7 rows from concept_synonym that already exist in the database\n",
      "Dropping 7 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 4 rows from concept_synonym that already exist in the database\n",
      "Dropping 5 rows from concept_synonym that already exist in the database\n",
      "Dropping 10 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 7 rows from concept_synonym that already exist in the database\n",
      "Dropping 10 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 16 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 5 rows from concept_synonym that already exist in the database\n",
      "Dropping 20 rows from concept_synonym that already exist in the database\n",
      "Dropping 8 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 4 rows from concept_synonym that already exist in the database\n",
      "Dropping 9 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 16 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 13 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 21 rows from concept_synonym that already exist in the database\n",
      "Dropping 6 rows from concept_synonym that already exist in the database\n",
      "Dropping 13 rows from concept_synonym that already exist in the database\n",
      "Dropping 6 rows from concept_synonym that already exist in the database\n",
      "Dropping 21 rows from concept_synonym that already exist in the database\n",
      "Dropping 8 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 5 rows from concept_synonym that already exist in the database\n",
      "Dropping 12 rows from concept_synonym that already exist in the database\n",
      "Dropping 10 rows from concept_synonym that already exist in the database\n",
      "Dropping 13 rows from concept_synonym that already exist in the database\n",
      "Dropping 4 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 13 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 7 rows from concept_synonym that already exist in the database\n",
      "Dropping 18 rows from concept_synonym that already exist in the database\n",
      "Dropping 9 rows from concept_synonym that already exist in the database\n",
      "Dropping 12 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 7 rows from concept_synonym that already exist in the database\n",
      "Dropping 29 rows from concept_synonym that already exist in the database\n",
      "Dropping 6 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 19 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 18 rows from concept_synonym that already exist in the database\n",
      "Dropping 4 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 21 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 4 rows from concept_synonym that already exist in the database\n",
      "Dropping 12 rows from concept_synonym that already exist in the database\n",
      "Dropping 4 rows from concept_synonym that already exist in the database\n",
      "Dropping 17 rows from concept_synonym that already exist in the database\n",
      "Dropping 8 rows from concept_synonym that already exist in the database\n",
      "Dropping 29 rows from concept_synonym that already exist in the database\n",
      "Dropping 10 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 17 rows from concept_synonym that already exist in the database\n",
      "Dropping 8 rows from concept_synonym that already exist in the database\n",
      "Dropping 18 rows from concept_synonym that already exist in the database\n",
      "Dropping 7 rows from concept_synonym that already exist in the database\n",
      "Dropping 9 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 7 rows from concept_synonym that already exist in the database\n",
      "Dropping 18 rows from concept_synonym that already exist in the database\n",
      "Dropping 7 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 16 rows from concept_synonym that already exist in the database\n",
      "Dropping 9 rows from concept_synonym that already exist in the database\n",
      "Dropping 24 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 9 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 14 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 8 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 4 rows from concept_synonym that already exist in the database\n",
      "Dropping 35 rows from concept_synonym that already exist in the database\n",
      "Dropping 10 rows from concept_synonym that already exist in the database\n",
      "Dropping 15 rows from concept_synonym that already exist in the database\n",
      "Dropping 9 rows from concept_synonym that already exist in the database\n",
      "Dropping 15 rows from concept_synonym that already exist in the database\n",
      "Dropping 5 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 12 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 16 rows from concept_synonym that already exist in the database\n",
      "Dropping 7 rows from concept_synonym that already exist in the database\n",
      "Dropping 17 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 5 rows from concept_synonym that already exist in the database\n",
      "Dropping 11 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 23 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 4 rows from concept_synonym that already exist in the database\n",
      "Dropping 15 rows from concept_synonym that already exist in the database\n",
      "Dropping 9 rows from concept_synonym that already exist in the database\n",
      "Dropping 7 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 7 rows from concept_synonym that already exist in the database\n",
      "Dropping 24 rows from concept_synonym that already exist in the database\n",
      "Dropping 8 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 8 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 7 rows from concept_synonym that already exist in the database\n",
      "Dropping 20 rows from concept_synonym that already exist in the database\n",
      "Dropping 10 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 16 rows from concept_synonym that already exist in the database\n",
      "Found 1 rows with unexpected nulls in concept_synonym.concept_synonym_name\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 18 rows from concept_synonym that already exist in the database\n",
      "Dropping 10 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 17 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 22 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 13 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 6 rows from concept_synonym that already exist in the database\n",
      "Dropping 23 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 12 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 13 rows from concept_synonym that already exist in the database\n",
      "Dropping 7 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 10 rows from concept_synonym that already exist in the database\n",
      "Dropping 6 rows from concept_synonym that already exist in the database\n",
      "Dropping 15 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 23 rows from concept_synonym that already exist in the database\n",
      "Dropping 9 rows from concept_synonym that already exist in the database\n",
      "Dropping 15 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 11 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 4 rows from concept_synonym that already exist in the database\n",
      "Dropping 21 rows from concept_synonym that already exist in the database\n",
      "Dropping 7 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 16 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 16 rows from concept_synonym that already exist in the database\n",
      "Dropping 11 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 17 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 17 rows from concept_synonym that already exist in the database\n",
      "Dropping 8 rows from concept_synonym that already exist in the database\n",
      "Dropping 17 rows from concept_synonym that already exist in the database\n",
      "Dropping 5 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 21 rows from concept_synonym that already exist in the database\n",
      "Dropping 6 rows from concept_synonym that already exist in the database\n",
      "Dropping 15 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 4 rows from concept_synonym that already exist in the database\n",
      "Dropping 18 rows from concept_synonym that already exist in the database\n",
      "Dropping 7 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 22 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 19 rows from concept_synonym that already exist in the database\n",
      "Dropping 5 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 22 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 18 rows from concept_synonym that already exist in the database\n",
      "Dropping 15 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 8 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 11 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 16 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 15 rows from concept_synonym that already exist in the database\n",
      "Dropping 4 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 9 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 4 rows from concept_synonym that already exist in the database\n",
      "Dropping 8 rows from concept_synonym that already exist in the database\n",
      "Dropping 4 rows from concept_synonym that already exist in the database\n",
      "Dropping 5 rows from concept_synonym that already exist in the database\n",
      "Dropping 9 rows from concept_synonym that already exist in the database\n",
      "Dropping 6 rows from concept_synonym that already exist in the database\n",
      "Dropping 5 rows from concept_synonym that already exist in the database\n",
      "Dropping 12 rows from concept_synonym that already exist in the database\n",
      "Dropping 12 rows from concept_synonym that already exist in the database\n",
      "Dropping 6 rows from concept_synonym that already exist in the database\n",
      "Dropping 18 rows from concept_synonym that already exist in the database\n",
      "Dropping 5 rows from concept_synonym that already exist in the database\n",
      "Dropping 22 rows from concept_synonym that already exist in the database\n",
      "Dropping 9 rows from concept_synonym that already exist in the database\n",
      "Dropping 6 rows from concept_synonym that already exist in the database\n",
      "Dropping 5 rows from concept_synonym that already exist in the database\n",
      "Dropping 7 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 13 rows from concept_synonym that already exist in the database\n",
      "Dropping 8 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 5 rows from concept_synonym that already exist in the database\n",
      "Dropping 13 rows from concept_synonym that already exist in the database\n",
      "Dropping 6 rows from concept_synonym that already exist in the database\n",
      "Dropping 13 rows from concept_synonym that already exist in the database\n",
      "Dropping 17 rows from concept_synonym that already exist in the database\n",
      "Dropping 7 rows from concept_synonym that already exist in the database\n",
      "Dropping 5 rows from concept_synonym that already exist in the database\n",
      "Dropping 13 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 9 rows from concept_synonym that already exist in the database\n",
      "Dropping 8 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 4 rows from concept_synonym that already exist in the database\n",
      "Dropping 4 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 14 rows from concept_synonym that already exist in the database\n",
      "Dropping 18 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Found 1 rows with unexpected nulls in concept_synonym.concept_synonym_name\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 9 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 12 rows from concept_synonym that already exist in the database\n",
      "Dropping 13 rows from concept_synonym that already exist in the database\n",
      "Dropping 4 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 6 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 9 rows from concept_synonym that already exist in the database\n",
      "Dropping 9 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 10 rows from concept_synonym that already exist in the database\n",
      "Dropping 10 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 13 rows from concept_synonym that already exist in the database\n",
      "Dropping 4 rows from concept_synonym that already exist in the database\n",
      "Dropping 5 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 4 rows from concept_synonym that already exist in the database\n",
      "Dropping 12 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 11 rows from concept_synonym that already exist in the database\n",
      "Dropping 9 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 4 rows from concept_synonym that already exist in the database\n",
      "Dropping 7 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 11 rows from concept_synonym that already exist in the database\n",
      "Dropping 9 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 4 rows from concept_synonym that already exist in the database\n",
      "Dropping 8 rows from concept_synonym that already exist in the database\n",
      "Dropping 5 rows from concept_synonym that already exist in the database\n",
      "Dropping 14 rows from concept_synonym that already exist in the database\n",
      "Dropping 6 rows from concept_synonym that already exist in the database\n",
      "Dropping 5 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 9 rows from concept_synonym that already exist in the database\n",
      "Dropping 10 rows from concept_synonym that already exist in the database\n",
      "Dropping 5 rows from concept_synonym that already exist in the database\n",
      "Dropping 23 rows from concept_synonym that already exist in the database\n",
      "Dropping 11 rows from concept_synonym that already exist in the database\n",
      "Dropping 8 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 4 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 14 rows from concept_synonym that already exist in the database\n",
      "Dropping 9 rows from concept_synonym that already exist in the database\n",
      "Dropping 5 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 4 rows from concept_synonym that already exist in the database\n",
      "Dropping 16 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 11 rows from concept_synonym that already exist in the database\n",
      "Dropping 10 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 6 rows from concept_synonym that already exist in the database\n",
      "Dropping 7 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 9 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 6 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 4 rows from concept_synonym that already exist in the database\n",
      "Dropping 6 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 14 rows from concept_synonym that already exist in the database\n",
      "Dropping 9 rows from concept_synonym that already exist in the database\n",
      "Dropping 4 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 8 rows from concept_synonym that already exist in the database\n",
      "Dropping 11 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 22 rows from concept_synonym that already exist in the database\n",
      "Dropping 8 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 7 rows from concept_synonym that already exist in the database\n",
      "Dropping 5 rows from concept_synonym that already exist in the database\n",
      "Dropping 4 rows from concept_synonym that already exist in the database\n",
      "Dropping 12 rows from concept_synonym that already exist in the database\n",
      "Dropping 9 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 8 rows from concept_synonym that already exist in the database\n",
      "Dropping 6 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 17 rows from concept_synonym that already exist in the database\n",
      "Dropping 9 rows from concept_synonym that already exist in the database\n",
      "Dropping 4 rows from concept_synonym that already exist in the database\n",
      "Dropping 13 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 15 rows from concept_synonym that already exist in the database\n",
      "Dropping 6 rows from concept_synonym that already exist in the database\n",
      "Dropping 13 rows from concept_synonym that already exist in the database\n",
      "Dropping 7 rows from concept_synonym that already exist in the database\n",
      "Dropping 21 rows from concept_synonym that already exist in the database\n",
      "Dropping 10 rows from concept_synonym that already exist in the database\n",
      "Dropping 13 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 14 rows from concept_synonym that already exist in the database\n",
      "Dropping 7 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 15 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 10 rows from concept_synonym that already exist in the database\n",
      "Dropping 7 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 17 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 17 rows from concept_synonym that already exist in the database\n",
      "Dropping 11 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 8 rows from concept_synonym that already exist in the database\n",
      "Dropping 4 rows from concept_synonym that already exist in the database\n",
      "Dropping 16 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 21 rows from concept_synonym that already exist in the database\n",
      "Dropping 4 rows from concept_synonym that already exist in the database\n",
      "Dropping 19 rows from concept_synonym that already exist in the database\n",
      "Dropping 5 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 8 rows from concept_synonym that already exist in the database\n",
      "Dropping 13 rows from concept_synonym that already exist in the database\n",
      "Dropping 8 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 18 rows from concept_synonym that already exist in the database\n",
      "Dropping 7 rows from concept_synonym that already exist in the database\n",
      "Dropping 26 rows from concept_synonym that already exist in the database\n",
      "Dropping 8 rows from concept_synonym that already exist in the database\n",
      "Dropping 14 rows from concept_synonym that already exist in the database\n",
      "Dropping 6 rows from concept_synonym that already exist in the database\n",
      "Dropping 32 rows from concept_synonym that already exist in the database\n",
      "Dropping 12 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 16 rows from concept_synonym that already exist in the database\n",
      "Dropping 11 rows from concept_synonym that already exist in the database\n",
      "Dropping 21 rows from concept_synonym that already exist in the database\n",
      "Dropping 4 rows from concept_synonym that already exist in the database\n",
      "Dropping 9 rows from concept_synonym that already exist in the database\n",
      "Dropping 5 rows from concept_synonym that already exist in the database\n",
      "Dropping 13 rows from concept_synonym that already exist in the database\n",
      "Dropping 6 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 18 rows from concept_synonym that already exist in the database\n",
      "Dropping 4 rows from concept_synonym that already exist in the database\n",
      "Dropping 9 rows from concept_synonym that already exist in the database\n",
      "Dropping 9 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 13 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 5 rows from concept_synonym that already exist in the database\n",
      "Dropping 14 rows from concept_synonym that already exist in the database\n",
      "Dropping 4 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 13 rows from concept_synonym that already exist in the database\n",
      "Dropping 10 rows from concept_synonym that already exist in the database\n",
      "Dropping 19 rows from concept_synonym that already exist in the database\n",
      "Dropping 5 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 9 rows from concept_synonym that already exist in the database\n",
      "Dropping 4 rows from concept_synonym that already exist in the database\n",
      "Dropping 18 rows from concept_synonym that already exist in the database\n",
      "Dropping 4 rows from concept_synonym that already exist in the database\n",
      "Dropping 4 rows from concept_synonym that already exist in the database\n",
      "Dropping 15 rows from concept_synonym that already exist in the database\n",
      "Dropping 9 rows from concept_synonym that already exist in the database\n",
      "Dropping 15 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 19 rows from concept_synonym that already exist in the database\n",
      "Dropping 6 rows from concept_synonym that already exist in the database\n",
      "Dropping 17 rows from concept_synonym that already exist in the database\n",
      "Dropping 7 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 17 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 8 rows from concept_synonym that already exist in the database\n",
      "Dropping 16 rows from concept_synonym that already exist in the database\n",
      "Dropping 18 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 17 rows from concept_synonym that already exist in the database\n",
      "Dropping 9 rows from concept_synonym that already exist in the database\n",
      "Dropping 6 rows from concept_synonym that already exist in the database\n",
      "Dropping 14 rows from concept_synonym that already exist in the database\n",
      "Dropping 10 rows from concept_synonym that already exist in the database\n",
      "Dropping 5 rows from concept_synonym that already exist in the database\n",
      "Dropping 7 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 4 rows from concept_synonym that already exist in the database\n",
      "Dropping 14 rows from concept_synonym that already exist in the database\n",
      "Dropping 9 rows from concept_synonym that already exist in the database\n",
      "Dropping 11 rows from concept_synonym that already exist in the database\n",
      "Dropping 4 rows from concept_synonym that already exist in the database\n",
      "Dropping 5 rows from concept_synonym that already exist in the database\n",
      "Dropping 10 rows from concept_synonym that already exist in the database\n",
      "Dropping 10 rows from concept_synonym that already exist in the database\n",
      "Dropping 4 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 11 rows from concept_synonym that already exist in the database\n",
      "Dropping 7 rows from concept_synonym that already exist in the database\n",
      "Dropping 4 rows from concept_synonym that already exist in the database\n",
      "Dropping 12 rows from concept_synonym that already exist in the database\n",
      "Dropping 8 rows from concept_synonym that already exist in the database\n",
      "Dropping 6 rows from concept_synonym that already exist in the database\n",
      "Dropping 7 rows from concept_synonym that already exist in the database\n",
      "Dropping 13 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 6 rows from concept_synonym that already exist in the database\n",
      "Dropping 13 rows from concept_synonym that already exist in the database\n",
      "Dropping 6 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 12 rows from concept_synonym that already exist in the database\n",
      "Dropping 7 rows from concept_synonym that already exist in the database\n",
      "Dropping 14 rows from concept_synonym that already exist in the database\n",
      "Dropping 20 rows from concept_synonym that already exist in the database\n",
      "Dropping 4 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 5 rows from concept_synonym that already exist in the database\n",
      "Dropping 15 rows from concept_synonym that already exist in the database\n",
      "Dropping 4 rows from concept_synonym that already exist in the database\n",
      "Dropping 13 rows from concept_synonym that already exist in the database\n",
      "Dropping 10 rows from concept_synonym that already exist in the database\n",
      "Dropping 7 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 8 rows from concept_synonym that already exist in the database\n",
      "Dropping 6 rows from concept_synonym that already exist in the database\n",
      "Dropping 4 rows from concept_synonym that already exist in the database\n",
      "Dropping 13 rows from concept_synonym that already exist in the database\n",
      "Dropping 14 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 10 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 19 rows from concept_synonym that already exist in the database\n",
      "Dropping 8 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 8 rows from concept_synonym that already exist in the database\n",
      "Dropping 8 rows from concept_synonym that already exist in the database\n",
      "Dropping 7 rows from concept_synonym that already exist in the database\n",
      "Dropping 15 rows from concept_synonym that already exist in the database\n",
      "Dropping 12 rows from concept_synonym that already exist in the database\n",
      "Dropping 5 rows from concept_synonym that already exist in the database\n",
      "Dropping 4 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 13 rows from concept_synonym that already exist in the database\n",
      "Dropping 10 rows from concept_synonym that already exist in the database\n",
      "Dropping 15 rows from concept_synonym that already exist in the database\n",
      "Dropping 8 rows from concept_synonym that already exist in the database\n",
      "Dropping 6 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 5 rows from concept_synonym that already exist in the database\n",
      "Dropping 12 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 15 rows from concept_synonym that already exist in the database\n",
      "Dropping 12 rows from concept_synonym that already exist in the database\n",
      "Dropping 10 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 6 rows from concept_synonym that already exist in the database\n",
      "Dropping 11 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 9 rows from concept_synonym that already exist in the database\n",
      "Dropping 11 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 5 rows from concept_synonym that already exist in the database\n",
      "Dropping 10 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 13 rows from concept_synonym that already exist in the database\n",
      "Dropping 15 rows from concept_synonym that already exist in the database\n",
      "Dropping 6 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 15 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 8 rows from concept_synonym that already exist in the database\n",
      "Dropping 14 rows from concept_synonym that already exist in the database\n",
      "Dropping 4 rows from concept_synonym that already exist in the database\n",
      "Dropping 8 rows from concept_synonym that already exist in the database\n",
      "Dropping 7 rows from concept_synonym that already exist in the database\n",
      "Dropping 13 rows from concept_synonym that already exist in the database\n",
      "Dropping 11 rows from concept_synonym that already exist in the database\n",
      "Dropping 11 rows from concept_synonym that already exist in the database\n",
      "Dropping 5 rows from concept_synonym that already exist in the database\n",
      "Found 1 rows with unexpected nulls in concept_synonym.concept_synonym_name\n",
      "Dropping 10 rows from concept_synonym that already exist in the database\n",
      "Dropping 12 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 8 rows from concept_synonym that already exist in the database\n",
      "Dropping 18 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 7 rows from concept_synonym that already exist in the database\n",
      "Dropping 18 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 14 rows from concept_synonym that already exist in the database\n",
      "Dropping 7 rows from concept_synonym that already exist in the database\n",
      "Dropping 5 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 5 rows from concept_synonym that already exist in the database\n",
      "Dropping 9 rows from concept_synonym that already exist in the database\n",
      "Dropping 4 rows from concept_synonym that already exist in the database\n",
      "Dropping 11 rows from concept_synonym that already exist in the database\n",
      "Dropping 17 rows from concept_synonym that already exist in the database\n",
      "Dropping 6 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 9 rows from concept_synonym that already exist in the database\n",
      "Dropping 11 rows from concept_synonym that already exist in the database\n",
      "Dropping 8 rows from concept_synonym that already exist in the database\n",
      "Dropping 12 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 4 rows from concept_synonym that already exist in the database\n",
      "Dropping 14 rows from concept_synonym that already exist in the database\n",
      "Dropping 5 rows from concept_synonym that already exist in the database\n",
      "Dropping 10 rows from concept_synonym that already exist in the database\n",
      "Dropping 12 rows from concept_synonym that already exist in the database\n",
      "Dropping 7 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 13 rows from concept_synonym that already exist in the database\n",
      "Dropping 15 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 8 rows from concept_synonym that already exist in the database\n",
      "Dropping 12 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 7 rows from concept_synonym that already exist in the database\n",
      "Dropping 14 rows from concept_synonym that already exist in the database\n",
      "Dropping 5 rows from concept_synonym that already exist in the database\n",
      "Dropping 11 rows from concept_synonym that already exist in the database\n",
      "Dropping 9 rows from concept_synonym that already exist in the database\n",
      "Dropping 4 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 9 rows from concept_synonym that already exist in the database\n",
      "Dropping 9 rows from concept_synonym that already exist in the database\n",
      "Dropping 4 rows from concept_synonym that already exist in the database\n",
      "Dropping 12 rows from concept_synonym that already exist in the database\n",
      "Dropping 9 rows from concept_synonym that already exist in the database\n",
      "Dropping 4 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 9 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 8 rows from concept_synonym that already exist in the database\n",
      "Dropping 14 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 2 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 11 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 5 rows from concept_synonym that already exist in the database\n",
      "Dropping 15 rows from concept_synonym that already exist in the database\n",
      "Dropping 4 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Found 1 rows with unexpected nulls in concept_synonym.concept_synonym_name\n",
      "Dropping 6 rows from concept_synonym that already exist in the database\n",
      "Dropping 9 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n",
      "Dropping 9 rows from concept_synonym that already exist in the database\n",
      "Dropping 7 rows from concept_synonym that already exist in the database\n",
      "Dropping 13 rows from concept_synonym that already exist in the database\n",
      "Dropping 5 rows from concept_synonym that already exist in the database\n",
      "Dropping 15 rows from concept_synonym that already exist in the database\n",
      "Dropping 3 rows from concept_synonym that already exist in the database\n",
      "Dropping 10 rows from concept_synonym that already exist in the database\n",
      "Dropping 5 rows from concept_synonym that already exist in the database\n",
      "Dropping 5 rows from concept_synonym that already exist in the database\n",
      "Dropping 1 rows from concept_synonym that already exist in the database\n"
     ]
    }
   ],
   "source": [
    "# for a fresh load db dupe checks that include db are super slow for the largest tables, \n",
    "# but synonym file is very dupe prone so just for this one...\n",
    "\n",
    "with bulk_load_context(session):\n",
    "    for model in [Concept_Synonym]:#ATHENA_SUBSEQUENT_LOAD:\n",
    "        _ = model.load_csv(\n",
    "            session,\n",
    "            base_path / f\"{model.__tablename__.upper()}.csv\",\n",
    "            dedupe=True,\n",
    "            chunksize=5000,\n",
    "            commit_on_chunk=True,\n",
    "            dedupe_incl_db=True\n",
    "        )\n",
    "        session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03484ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_by_domain = pd.DataFrame(\n",
    "    session.query(\n",
    "        *Concept.__table__.columns\n",
    "    )\n",
    "    .filter(\n",
    "        sa.or_(\n",
    "            Concept.domain_id.in_(['Gender', 'Ethnicity', 'Race', 'Visit', 'Location', 'Provider', 'Type Concept']),\n",
    "            sa.and_(\n",
    "                Concept.domain_id == 'Condition',\n",
    "                Concept.vocabulary_id == 'ICDO3'\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f38f31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "avail_gender = list(concept_by_domain[concept_by_domain.domain_id=='Gender'].concept_id)\n",
    "avail_ethnicity = list(concept_by_domain[concept_by_domain.domain_id=='Ethnicity'].concept_id)\n",
    "avail_race = list(concept_by_domain[concept_by_domain.domain_id=='Race'].concept_id)\n",
    "avail_place_of_service = list(concept_by_domain[concept_by_domain.domain_id=='Visit'].concept_id)\n",
    "avail_country = list(concept_by_domain[concept_by_domain.concept_class_id=='Location'].concept_id)\n",
    "avail_provider = list(concept_by_domain[concept_by_domain.domain_id=='Provider'].concept_id)\n",
    "avail_types = list(concept_by_domain[concept_by_domain.domain_id=='Type Concept'].concept_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea2252e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cancers = list(concept_by_domain[(concept_by_domain.domain_id=='Condition')&(concept_by_domain.vocabulary_id=='ICDO3') & (concept_by_domain.concept_code.str.contains('/3'))].concept_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eac7991f",
   "metadata": {},
   "outputs": [],
   "source": [
    "staging_parents = pd.DataFrame(\n",
    "    session.query(\n",
    "        *Concept.__table__.columns\n",
    "    )\n",
    "    .join(Concept_Ancestor, Concept.concept_id==Concept_Ancestor.descendant_concept_id)\n",
    "    .filter(Concept_Ancestor.ancestor_concept_id==734320)\n",
    "    .filter(Concept_Ancestor.max_levels_of_separation==1)\n",
    ")\n",
    "\n",
    "staging_sets = {}\n",
    "\n",
    "for axis in ['T', 'N', 'M', 'Stage']:\n",
    "    parents = list(staging_parents[staging_parents.concept_name.str.contains(axis)].concept_id)\n",
    "    s = pd.DataFrame(\n",
    "        session.query(\n",
    "            *Concept.__table__.columns\n",
    "        )\n",
    "        .join(Concept_Ancestor, Concept.concept_id==Concept_Ancestor.descendant_concept_id)\n",
    "        .filter(Concept_Ancestor.ancestor_concept_id.in_(parents))\n",
    "        .filter(Concept.concept_code.ilike('%8th%'))\n",
    "        .filter(~Concept.concept_code.ilike('%yp%'))\n",
    "    )\n",
    "    staging_sets[axis] = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41e86f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirming string hack to identify staging axes does work as expected\n",
    "# staging_sets['Stage'].concept_code.map(lambda x: x.split('-')[-1]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc70fc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are super-naive and brute-force ways to populate very basic test data - good enough for now - better content coming\n",
    "\n",
    "def populate_reference_data(session):\n",
    "    \n",
    "    loc_ids = Location.allocator(session)\n",
    "    cs_ids = Care_Site.allocator(session)\n",
    "    pro_ids = Provider.allocator(session)\n",
    "    \n",
    "    location_data = [{'location_id': loc_ids.next(), 'country_concept_id': choice(avail_country), 'city': f'City {idx}'} for idx in range(10)]\n",
    "    locations = [Location(**row) for row in location_data]\n",
    "    care_site_data = [{'care_site_id': cs_ids.next(), 'care_site_name': f'Care Site {idx}', 'location_id': choice(locations).location_id, 'place_of_service_concept_id': choice(avail_place_of_service)} for idx in range(30)]\n",
    "    care_sites = [Care_Site(**row) for row in care_site_data]\n",
    "    provider_data = [{'provider_id': pro_ids.next(), 'specialty_concept_id': choice(avail_provider), 'gender_concept_id': choice(avail_gender), 'care_site_id': choice(care_sites).care_site_id} for _ in range(50)]\n",
    "    providers = [Provider(**row) for row in provider_data]\n",
    "\n",
    "    session.add_all(locations)\n",
    "    session.add_all(care_sites)\n",
    "    session.add_all(providers)\n",
    "    session.commit()\n",
    "\n",
    "    return locations, care_sites, providers\n",
    "\n",
    "def populate_people_and_visits(session, care_sites):\n",
    "    \n",
    "    person_ids = Person.allocator(session)\n",
    "    visit_ids = Visit_Occurrence.allocator(session)\n",
    "    \n",
    "    person_data = [{'person_id': person_ids.next(), 'year_of_birth': randint(1950, 2020), 'month_of_birth': randint(1, 12), 'gender_concept_id':choice(avail_gender), 'race_concept_id':choice(avail_race), 'ethnicity_concept_id':choice(avail_ethnicity)} for idx in range(1000)]\n",
    "    people = [Person(**row) for row in person_data]\n",
    "\n",
    "    visits = []\n",
    "    for person in people:\n",
    "        cs = choice(care_sites)\n",
    "        visit_num = randint(1, 3)\n",
    "        for v in range(visit_num):\n",
    "            days_delay = randint(0, 365)\n",
    "            visit_date = date(2020, 1, 1) + timedelta(days_delay)\n",
    "            visit = Visit_Occurrence(\n",
    "                visit_occurrence_id=visit_ids.next(),\n",
    "                person_id=person.person_id,\n",
    "                care_site_id=cs.care_site_id,\n",
    "                visit_concept_id=choice(avail_place_of_service),\n",
    "                visit_start_date=visit_date,\n",
    "                visit_end_date=visit_date,\n",
    "            )\n",
    "            visits.append(visit)\n",
    "    session.add_all(people)\n",
    "    session.add_all(visits)\n",
    "    session.commit()\n",
    "    return people, visits\n",
    "\n",
    "def populate_observation_periods(session):\n",
    "    op_ids = Observation_Period.allocator(session)\n",
    "    deaths = []\n",
    "    rows = (\n",
    "        session.query(\n",
    "            Visit_Occurrence.person_id,\n",
    "            sa.func.min(Visit_Occurrence.visit_start_date).label(\"start\"),\n",
    "            sa.func.max(Visit_Occurrence.visit_end_date).label(\"end\"),\n",
    "            Death.death_date,\n",
    "            Observation_Period.observation_period_id\n",
    "        )\n",
    "        .join(Death, Death.person_id==Visit_Occurrence.person_id, isouter=True)\n",
    "        .join(Observation_Period, Observation_Period.person_id==Visit_Occurrence.person_id, isouter=True)\n",
    "        .filter(Observation_Period.observation_period_id==None)\n",
    "        .group_by(Visit_Occurrence.person_id)\n",
    "        .all()\n",
    "    )\n",
    "    obs = []\n",
    "    for idx, r in enumerate(rows):\n",
    "        deceased = np.random.choice([True, False], p=[0.05, 0.95])\n",
    "        if deceased:\n",
    "            death_date = r.end + timedelta(days=randint(1, 365))\n",
    "            deaths.append(\n",
    "                Death(\n",
    "                    person_id=r.person_id,\n",
    "                    death_date=death_date,\n",
    "                    death_type_concept_id=choice(avail_types),\n",
    "                )\n",
    "            )\n",
    "            obs_end = death_date\n",
    "        else:\n",
    "            obs_end = r.end\n",
    "        obs.append(\n",
    "            Observation_Period(\n",
    "                observation_period_id=op_ids.next(),\n",
    "                person_id=r.person_id,\n",
    "                observation_period_start_date=r.start,\n",
    "                observation_period_end_date=obs_end,\n",
    "                period_type_concept_id=choice(avail_types),\n",
    "            )\n",
    "        )\n",
    "    session.add_all(deaths)\n",
    "    session.add_all(obs)\n",
    "    session.commit()\n",
    "    return obs\n",
    "\n",
    "def populate_conditions_and_modifiers(session):\n",
    "    cond_ids = Condition_Occurrence.allocator(session)\n",
    "    meas_ids = Measurement.allocator(session)\n",
    "    ep_ids   = Episode.allocator(session)\n",
    "    rows = (\n",
    "        session.query(\n",
    "            Observation_Period, Death, Condition_Occurrence\n",
    "        )\n",
    "        .join(Death, Observation_Period.person_id==Death.person_id, isouter=True)\n",
    "        .join(Condition_Occurrence, Observation_Period.person_id==Condition_Occurrence.person_id, isouter=True)\n",
    "        .all()\n",
    "    )\n",
    "    conditions = []\n",
    "    measurements = []\n",
    "    episodes = []\n",
    "    episode_events = []\n",
    "    for obs, death, condition in rows:\n",
    "        if condition:\n",
    "            continue\n",
    "        t = choice(list(staging_sets['T'].concept_id))\n",
    "        n = choice(list(staging_sets['N'].concept_id))\n",
    "        m = choice(list(staging_sets['M'].concept_id))\n",
    "        # don't worry abt overall stage for now as it should be calculated\n",
    "        condition_concept = choice(cancers)\n",
    "        condition = Condition_Occurrence(\n",
    "            condition_occurrence_id=cond_ids.next(),\n",
    "            condition_concept_id = condition_concept,\n",
    "            condition_start_date = obs.observation_period_start_date,\n",
    "            condition_type_concept_id = choice(avail_types),\n",
    "            person_id = obs.person_id,\n",
    "            condition_status_concept_id = 32902\n",
    "        )\n",
    "        conditions.append(condition)\n",
    "        episode = Episode(\n",
    "            episode_id=ep_ids.next(),\n",
    "            person_id=obs.person_id,\n",
    "            episode_concept_id=32533,  # Episode of care\n",
    "            episode_object_concept_id=condition.condition_concept_id,\n",
    "            episode_start_date=condition.condition_start_date,\n",
    "            episode_end_date=(\n",
    "                death.death_date if death else obs.observation_period_end_date\n",
    "            ),\n",
    "            episode_type_concept_id=choice(avail_types),  # EHR / registry / derived\n",
    "        )\n",
    "        episodes.append(episode)\n",
    "\n",
    "        for stage in [t, n, m]:\n",
    "            measurement = Measurement(\n",
    "                person_id = obs.person_id,\n",
    "                measurement_id = meas_ids.next(),\n",
    "                measurement_concept_id = stage,\n",
    "                measurement_event_id = condition.condition_occurrence_id,\n",
    "                meas_event_field_concept_id = 1147127, # condition_occurrence.condition_occurrence_id\n",
    "                measurement_date = condition.condition_start_date,\n",
    "                measurement_type_concept_id = choice(avail_types),\n",
    "                value_as_number = 1\n",
    "            )\n",
    "            measurements.append(measurement)\n",
    "            episode_events.append(\n",
    "                Episode_Event(\n",
    "                    episode_id=episode.episode_id,\n",
    "                    event_id=measurement.measurement_id,\n",
    "                    episode_event_field_concept_id=1147138,  # measurement.measurement_id\n",
    "                )\n",
    "            )\n",
    "        episode_events.append(\n",
    "            Episode_Event(\n",
    "                episode_id=episode.episode_id,\n",
    "                event_id=condition.condition_occurrence_id,\n",
    "                episode_event_field_concept_id=1147127,  # condition_occurrence.condition_occurrence_id\n",
    "            )\n",
    "        )\n",
    "    session.add_all(conditions)\n",
    "    session.add_all(measurements)\n",
    "    session.add_all(episodes)\n",
    "    session.add_all(episode_events)\n",
    "    session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7ccb46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Session() as sess:\n",
    "    populate_reference_data(sess)\n",
    "    sess.commit()\n",
    "    care_sites = sess.query(Care_Site).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97d76a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Session() as sess:\n",
    "    populate_people_and_visits(sess, care_sites)\n",
    "    populate_observation_periods(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e57318e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Session() as sess:\n",
    "    populate_conditions_and_modifiers(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a241ac28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omop-alchemy (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
